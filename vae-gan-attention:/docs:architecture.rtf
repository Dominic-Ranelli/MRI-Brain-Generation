{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 # VAE-GAN Architecture with Attention\
\
## Overview\
\
Model uses two-part architecture:\
\
\'97 Variational Autoencoder (VAE): Encodes input medical images into a latent space and reconstructs them.\
\'97 GAN Discriminator: Judges real vs. generated images, improving realism.\
\'97 Attention Modules: Enhance decoder\'92s ability to focus on important spatial/semantic features.\
\
## Components\
\
\'97 Encoder: Convolutional layers + ReLU, encodes into mean and log variance\
\'97 Latent Sampling: z = mu + sigma * epsilon\
\'97 Decoder: Upsampling layers with optional attention\
\'97 Discriminator: Trains adversarially to guide output toward realism\
\
## Loss Functions\
\
\'97 VAE Loss = MSE (Reconstruction) + KL Divergence\
\'97 GAN Loss = Binary Cross Entropy between fake/real images\
}